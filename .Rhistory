break
}else {
books <- data.frame(title = title, writer = writer, price = price)
computer_books <- rbind.data.frame(computer_books,books)
}
}
View(computer_books)
computer_books <- data.frame()
base_url <- "http://www.hanbit.co.kr/academy/books/category_list.html?"
page <- 'page='
category <-  "&cate_cd=004007&srt=p_pub_date"
for (i in 1:6) {
url <- paste0(base_url,page,i,category)
html <- read_html(url)
html
book_list <- html_node(html,'.sub_book_list_area')
book_list
lis <- html_nodes(book_list, "li")
html %>%
html_node('.sub_book_list_area') %>%
html_nodes('li') -> lis
lis
price <- c()
title <- c()
writer <- c()
for (li in lis) {
pr <- html_node(li, '.price') %>% html_text()
pr <- gsub('\\\\',"",pr)
price <- c(price,pr)
title <- c(title, html_node(li, '.book_tit') %>% html_text())
writer <- c(writer,html_node(li, '.book_writer') %>% html_text())
#cat(title, writer, price, '\n')
}
books <- data.frame(title = title, writer = writer, price = price)
computer_books <- rbind.data.frame(computer_books,books)
}
View(computer_books)
for (i in 1:10) {
url <- paste0(base_url,page,i,category)
html <- read_html(url)
html
book_list <- html_node(html,'.sub_book_list_area')
book_list
lis <- html_nodes(book_list, "li")
price <- c()
title <- c()
writer <- c()
for (li in lis) {
pr <- html_node(li, '.price') %>% html_text()
pr <- gsub('\\\\',"",pr)
price <- c(price,pr)
title <- c(title, html_node(li, '.book_tit') %>% html_text())
writer <- c(writer,html_node(li, '.book_writer') %>% html_text())
#cat(title, writer, price, '\n')
}
if(is.null(price)) {
break
}else {
books <- data.frame(title = title, writer = writer, price = price)
IT_books <- rbind.data.frame(IT_books,books)
}
}
programming_books <- data.frame()
#finding the link and list of categories
text <- read_html(base_url)
category_list <- html_nodes(text, ".node_body")
category_list
category_list <- html_nodes(text, ".category_books")
category_list
text
View(text)
html <- read_html(url)
html
category_list <- html_nodes(text, ".lnb_area") %>% html_nodes('li')
category_list
View(category_list)
lis
category_list
link <- c()
category_name <- c()
category_list1 <- for(li in category_list) {
link <- c(link,html_node(category_list,'category_books') %>% html_text())
#category_name <-
}
category_list1
category_list1 <- for(li in category_list) {
link <- c(link,html_node(category_list,'category_books') %>% html_text())
#category_name <-
}
category_list1
html_node(category_list,'.category_books')
html_node(category_list,'category_books')
html_node(category_list,'category_books')
category
category_list
html_node(category_list,'category_books')
html_node(category_list,'li')
html_nodes(category_list,'li')
html_category %>% html_nodes('li') %>%
link <- gsub("<li><a href=","",li)
html_category <- category_list %>% html_nodes('li') %>%
link <- gsub("<li><a href=","",li)
html_category <- category_list %>%
html_nodes('li') %>%
link <- gsub("<li><a href=","",li)
html_category <- category_list %>%
html_nodes('li') %>%
link <- gsub("<li><a href=","",li)
html_category <- category_list %>%
html_nodes('li') #%>%
html_category
link <- gsub("<li><a href=","",li)
li
link
link <- gsub(">+")
link <- gsub(">+","",li)
link
link <- gsub(">","",li)
link
link <- gsub("<li><a href=","",li)
link
link <- gsub(">전체도서목록","",li)
link
link <- gsub("http://www.hanbit.co.kr/academy/books/category_list.html?","",li)
link
link <- gsub("<li><a href=","",html_category)
link
link <- gsub("http://www.hanbit.co.kr/academy/books/category_list.html?","",li)
link
link <- gsub("http://www.hanbit.co.kr/academy/books/category_list.html?","",html_category)
link
link <- gsub("<li><a href=\"?http://www.hanbit.co.kr/academy/books/category_list.html?","",html_category)
link
link <- gsub("</a></li>",""link)
link
link <- gsub("</a></li>","",link)
link
link <-substr(link,1,13)
link
link <- gsub("<li><a href=\"?http://www.hanbit.co.kr/academy/books/category_list.html?","",html_category)
link <- gsub("</a></li>","",link)
link <-substr(link,1,16)
link
category_list1 <-substr(link,1,16)
clas(category_list1)
class(category_list1)
as.data.frame(category_list1)
catagory_list1 <- gsub("?","&",category_list1)
category_list1
category_list1 <- gsub("?","&",category_list1)
category_list1
catagory_list1 <- gsub("?","&",category_list1)
library(rvest)
library(stringr)
library(dplyr)
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
url_base <- 'https://movie.naver.com'
start_url <- "/movie/bi/mi/point.nhn?code=173123#tab"
url <- paste0(url_base,start_url, encoding="euc-kr")
html <- read_html(url)
html %>%
html_node('iframe.ifr') %>%
html_attr('src') -> url2
url2
page <- "&page="
score <- c()
review <- c()
writer <- c()
time <- c()
ifr_url <- paste0(url_base, url2,page,i)
html2 <- read_html(ifr_url)
html2 %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
for (li in lis) {
score <- c(score, html_node(li, '.star_score') %>% html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> tmp
idx <- str_locate(tmp, "\r")
review <- c(review, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
writer <- c(writer, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
time <- c(time, str_sub(tmp, 1, idx[1]-1))
#print(time)
}
}
review = data.frame(score=score, review=review, writer=writer, time=time)
View(review)
ifr_url
score <- c()
review <- c()
writer <- c()
time <- c()
page <- "&page="
for(i in 1:250){
ifr_url
ifr_url <- paste0(url_base, url2,page,i)
html2 <- read_html(ifr_url)
html2 %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
for (li in lis) {
score <- c(score, html_node(li, '.star_score') %>% html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> tmp
idx <- str_locate(tmp, "\r")
review <- c(review, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
writer <- c(writer, str_sub(tmp, 1, idx[1]-1))
tmp <- trim(str_sub(tmp, idx[1], -1))
idx <- str_locate(tmp, "\r")
time <- c(time, str_sub(tmp, 1, idx[1]-1))
#print(time)
}
}
review = data.frame(score=score, review=review, writer=writer, time=time)
View(review)
mean(review$score)
mean(review$score,na.rm=T)
class(review$score)
naver_score <- review$score
naver_score <- review$score
naver_score <- as.numeric(naver_score)
mean(naver_score)
naver_score
review$score
View(review$score)
naver_score <- as.numerica(review$score)
naver_score <- as.numeric(review$score)
naver_score
mean(naver_score)
url2
naver_score <- as.double(naver_score)
naver_score
mean(naver_score
mean(naver_score)
mean(naver_score)
review$score_asnum <- as.numeric(review$score)
review$score_asnum
View(review$score_asnum)
review$score_asnum <- as.numeric(as.character(review$score))
review$score_asnum
View(review$score_asnum)
mean(review$score_asnum)
View(review)
cat_names = c('컴퓨터공학', '정보통신_전기_전자', '수학_과학_공학', '프로그래밍_웹',
'그래픽_디자인', 'OA_활용', '전기기본서', '전기기사',
'전기산업기사', '전기공사기사', '전기공사산업기사')
categories = c('004007', '004008', '004003', '004004', '004005', '004006',
'005005', '005001', '005002', '005003', '005004')
pages = c(6, 4, 3, 3, 1, 2, 2, 2, 1, 1, 1)
base_url <- 'http://www.hanbit.co.kr/academy/books/category_list.html?'
page <- 'page='
category <- '&cate_cd='
sort <- '&srt=p_pub_date'
wb <- createWorkbook()
View(df)
for (i in 1:6) {
for (j in 1:10) {
url <- paste0(base_url,category[i], j)
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text())
article <- c(article,title)
}
df[,i] <- data.frame(article = article)
}
article <- c()
for (i in 1:6) {
for (j in 1:10) {
url <- paste0(base_url,category[i], j)
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text())
article <- c(article,title)
}
df[,i] <- data.frame(article = article)
}
df <- data.frame()
{
df <- data.frame()
for (j in 1:10) {
url <- paste0(base_url,category[i], j)
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text())
article <- c(article,title)
}
books <- data.frame(aritcle = article)
df.books <- rbind(df.books,books)
}
df.books <- data.frame()
df.books <- data.frame()
for (j in 1:10) {
url <- paste0(base_url,category[i], j)
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text())
article <- c(article,title)
}
books <- data.frame(aritcle = article)
df.books <- rbind(df.books,books)
View(df.books)
base_url <- 'https://kr.investing.com/news/'
url <- paste0(base_url, 1)
category <- c('economy-news/','stock-market-news/','economic-indicators/',
'commodities-news/','forex-news/','cryptocurrency-news/')
for (i in 1:6) {
df.books <- data.frame()
for (j in 1:10) {
url <- paste0(base_url,category[i], j)
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text())
article <- c(article,title)
}
books <- data.frame(aritcle = article)
df.books <- rbind(df.books,books)
}
#Wordcloud
library(KoNLP)
write(article, "data.txt")
data <- readLines('data.txt')
data1 <- sapply(data, extractNoun, USE.NAMES = F)
data3 <- unlist(data1)
data3 <- gsub("\\d+","",data3) ## 숫자 없애기
data3 <- gsub("서울시","",data3)
data3 <- gsub("서울","",data3)
data3 <- gsub("곡성","",data3)
data3 <- gsub("세종","",data3)
data3 <- gsub("-","",data3)
data3 <- gsub("부터","",data3)
data3 <- gsub("전","",data3)
data3 <- gsub("일","",data3)
data3 <- gsub("시간","",data3)
data3 <- gsub("월","",data3)
data3 <- gsub("뉴스핌<U+A><U+A>","",data3)
data3 <- gsub("기","",data3)
data3 <- gsub("원","",data3)
data3 <- gsub("한","",data3)
data3 <- gsub("\\.","",data3)
data3 <- gsub("\\[]","",data3)
data3 <- Filter(function(x) {nchar(x) >= 2}, data3) #2글자 이상 필터
data4 <- str_replace_all(data3, "[^[:alpha:]]","") #한글, 영어이외는 삭제
data4 <- gsub("UAUA","",data4)
txt2 <- readLines("경제gsub.txt")
for(i in 1:length(txt2)) {
data3 <- gsub(txt2[i],"",data3)
}
write(data4,"economy.txt")
data5 <- read.table("economy.txt")
nrow(data5)
wordcount <- table(data5)
wordcloud <-sort(wordcount,decreasing = T)
head(wordcloud)
wordcloud2(wordcloud)
library(wordcloud2)
library(wordcloud)
wordcloud(wordcloud)
wordcloud(wordcloud(names(wordcount), freq=wordcount, scale=c(5,1), rot.per=0.25, min.freq = 2,
random.order = F, random.color =  T, colors = palete))
palete <- brewer.pal(9, "Set2")
palete <- brewer.pal(7, "Set2")
wordcloud(wordcloud(names(wordcount), freq=wordcount, scale=c(5,1), rot.per=0.25, min.freq = 2,
random.order = F, random.color =  T, colors = palete))
wordclou2(wordcloud)
wordcloud2(wordcloud)
wordcloud2(wordcloud,backgroundColor = "black")
wordcloud2(wordcloud,backgroundColor = "orange")
wordcloud2(wordcloud,backgroundColor = "black")
top10 <- head(worldcloud,10)
knitr::opts_chunk$set(echo = TRUE)
top10 <- head(worldcloud,10)
knitr::opts_chunk$set(echo = TRUE)
setwd("d:/workspace/R_Crawling/")
library(rvest)
library(dplyr)
library(stringr)
library(openxlsx)
library(wordcloud2)
library(wordcloud)
library(KoNLP)
trim <- function(x) gsub("^\\s+|\\s+$", "", x)
base_url <- 'https://kr.investing.com/news/'
category <- c('economy-news/','stock-market-news/','economic-indicators/',
'commodities-news/','forex-news/','cryptocurrency-news/')
df <- c()
article <- c()
for (i in 1:6) {
df.books <- data.frame()
for (j in 1:10) {
url <- paste0(base_url,category[i], j)
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text())
article <- c(article,title)
}
books <- data.frame(aritcle = article)
df.books <- rbind(df.books,books)
}
knitr::opts_chunk$set(echo = TRUE)
setwd("d:/workspace/R_Crawling/과제/과제제출/")
library(rvest)
library(dplyr)
library(stringr)
library(openxlsx)
library(wordcloud2)
library(wordcloud)
library(KoNLP)
trim <- function(x) gsub("^\\s+|\\s+$", "", x)
base_url <- 'https://kr.investing.com/news/'
category <- c('economy-news/','stock-market-news/','economic-indicators/',
'commodities-news/','forex-news/','cryptocurrency-news/')
df <- c()
article <- c()
for (i in 1:6) {
df.books <- data.frame()
for (j in 1:10) {
url <- paste0(base_url,category[i], j)
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text())
article <- c(article,title)
}
books <- data.frame(aritcle = article)
df.books <- rbind(df.books,books)
}
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text());title
article <- c()
df.article <- data.frame()
for (i in 1:10) {
url <- paste0(base_url, i)
html <- read_html(url)
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text())
article <- c(article,title)
}
trim <- function(x) gsub("^\\s+|\\s+$", "", x)
base_url <- 'https://kr.investing.com/news/'
category <- c('economy-news/','stock-market-news/','economic-indicators/',
'commodities-news/','forex-news/','cryptocurrency-news/')
df <- c()
article <- c()
for (i in 1:6) {
df.books <- data.frame()
for (j in 1:10) {
url <- paste0(base_url,category[i], j)
html <- read_html(url)
html1 <- html_nodes(html,".wrapper");html1
title <- trim(html_nodes(html1, ".textDiv") %>% html_text())
article <- c(article,title)
}
books <- data.frame(aritcle = article)
df.books <- rbind(df.books,books)
}
#View(article)
#Wordcloud
write(article, "data.txt")
data <- readLines('data.txt')
data1 <- sapply(data, extractNoun, USE.NAMES = F)
data3 <- unlist(data1)
data3 <- gsub("\\d+","",data3) ## 숫자 없애기
data3 <- gsub("서울시","",data3)
data3 <- gsub("서울","",data3)
data3 <- gsub("곡성","",data3)
data3 <- gsub("세종","",data3)
data3 <- gsub("-","",data3)
data3 <- gsub("부터","",data3)
data3 <- gsub("전","",data3)
data3 <- gsub("일","",data3)
data3 <- gsub("시간","",data3)
data3 <- gsub("월","",data3)
data3 <- gsub("뉴스핌<U+A><U+A>","",data3)
data3 <- gsub("기","",data3)
data3 <- gsub("원","",data3)
data3 <- gsub("한","",data3)
data3 <- gsub("\\.","",data3)
data3 <- gsub("\\[]","",data3)
data3 <- Filter(function(x) {nchar(x) >= 2}, data3) #2글자 이상 필터
data4 <- str_replace_all(data3, "[^[:alpha:]]","") #한글, 영어이외는 삭제
data4 <- gsub("UAUA","",data4)
txt2 <- readLines("경제gsub.txt")
for(i in 1:length(txt2)) {
data3 <- gsub(txt2[i],"",data3)
}
write(data4,"economy.txt")
data5 <- read.table("economy.txt")
nrow(data5)
wordcount <- table(data5)
wordcloud <-sort(wordcount,decreasing = T)
head(wordcloud)
palete <- brewer.pal(7, "Set2")
#wordcloud(wordcloud(names(wordcount), freq=wordcount, scale=c(5,1), rot.per=0.25, min.freq = 2, random.order = F, random.color =  T, #colors = palete))
wordcloud2(wordcloud,backgroundColor = "black")
# 총 데이터 건수로부터 총 페이지수 구하기
html2 %>%
html_node('div.score_total') %>%
html_nodes('em') -> ems
write.csv(review,"spiderman_review.csv")
setwd('d:/workspace/R_Crawling/')
write.csv(review,"spiderman_review.csv")
